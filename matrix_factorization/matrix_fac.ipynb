{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tempfile import TemporaryDirectory\n",
    "import time\n",
    "from torch.optim import lr_scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data/ml-100k\"\n",
    "\n",
    "def read_data_ml100k(data_dir:str)->tuple[pd.DataFrame,int,int]:\n",
    "    names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "    data = pd.read_csv(os.path.join(data_dir, 'u.data'), sep='\\t',\n",
    "                       names=names, engine='python')\n",
    "    num_users = data.user_id.unique().shape[0]\n",
    "    num_items = data.item_id.unique().shape[0]\n",
    "    return data, num_users, num_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of users: 943, number of items: 1682\n",
      "matrix sparsity: 0.936953\n",
      "   user_id  item_id  rating  timestamp\n",
      "0      196      242       3  881250949\n",
      "1      186      302       3  891717742\n",
      "2       22      377       1  878887116\n",
      "3      244       51       2  880606923\n",
      "4      166      346       1  886397596\n"
     ]
    }
   ],
   "source": [
    "data, num_users, num_items = read_data_ml100k(DATA_DIR)\n",
    "sparsity:int = 1 - len(data) / (num_users * num_items)\n",
    "print(f'number of users: {num_users}, number of items: {num_items}')\n",
    "print(f'matrix sparsity: {sparsity:f}')\n",
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data['rating'], bins=5, ec='black')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Ratings in MovieLens 100K')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_ml100k(data: pd.DataFrame, num_users: int, num_items: int,\n",
    "                      split_mode: str = 'random', test_ratio: float = 0.1) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Split the dataset into training and testing sets in either random mode or sequence-aware mode.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pd.DataFrame\n",
    "        The dataset containing user-item interactions. Expected columns are user_id, item_id, rating, and timestamp.\n",
    "    num_users : int\n",
    "        The number of unique users in the dataset.\n",
    "    num_items : int\n",
    "        The number of unique items in the dataset.\n",
    "    split_mode : str, optional\n",
    "        The mode of splitting the data. Can be 'random' or 'seq-aware'. Default is 'random'.\n",
    "    test_ratio : float, optional\n",
    "        The ratio of the dataset to be used as the test set. Only used if split_mode is 'random'. Default is 0.1.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    tuple[pd.DataFrame, pd.DataFrame]\n",
    "        A tuple containing the training and testing datasets as pandas DataFrames.\n",
    "    \"\"\"\n",
    "    if split_mode == 'seq-aware':\n",
    "        train_items, test_items, train_list = {}, {}, []\n",
    "        for line in data.itertuples():\n",
    "            u, i, rating, time = line[1], line[2], line[3], line[4]\n",
    "            train_items.setdefault(u, []).append((u, i, rating, time))\n",
    "            if u not in test_items or test_items[u][-1] < time:\n",
    "                test_items[u] = (i, rating, time)\n",
    "        for u in range(1, num_users + 1):\n",
    "            train_list.extend(sorted(train_items[u], key=lambda k: k[3]))\n",
    "        test_data = [(key, *value) for key, value in test_items.items()]\n",
    "        train_data = [item for item in train_list if item not in test_data]\n",
    "        train_data = pd.DataFrame(train_data)\n",
    "        test_data = pd.DataFrame(test_data)\n",
    "    else:\n",
    "        mask = [True if x == 1 else False for x in np.random.uniform(\n",
    "            0, 1, (len(data))) < 1 - test_ratio]\n",
    "        neg_mask = [not x for x in mask]\n",
    "        train_data, test_data = data[mask], data[neg_mask]\n",
    "    return train_data, test_data\n",
    "\n",
    "def load_data_ml100k(data: pd.DataFrame, num_users: int, num_items: int, feedback: str = 'explicit') -> tuple[list[int], list[int], list[int], np.ndarray | dict]:\n",
    "    \"\"\"\n",
    "    Load the dataset and convert it into user-item interaction matrices.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pd.DataFrame\n",
    "        The dataset containing user-item interactions. Expected columns are user_id, item_id, and rating.\n",
    "    num_users : int\n",
    "        The number of unique users in the dataset.\n",
    "    num_items : int\n",
    "        The number of unique items in the dataset.\n",
    "    feedback : str, optional\n",
    "        The type of feedback. Can be 'explicit' or 'implicit'. Default is 'explicit'.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    tuple[list[int], list[int], list[int], np.ndarray | dict]\n",
    "        A tuple containing:\n",
    "        - users: List of user indices.\n",
    "        - items: List of item indices.\n",
    "        - scores: List of scores (ratings or implicit feedback).\n",
    "        - inter: User-item interaction matrix. If feedback is 'explicit', this is a 2D numpy array.\n",
    "                 If feedback is 'implicit', this is a dictionary where keys are user indices and values are lists of item indices.\n",
    "    \"\"\"\n",
    "    users, items, scores = [], [], []\n",
    "    inter = np.zeros((num_items, num_users)) if feedback == 'explicit' else {}\n",
    "    for line in data.itertuples():\n",
    "        user_index, item_index = int(line[1] - 1), int(line[2] - 1)\n",
    "        score = int(line[3]) if feedback == 'explicit' else 1\n",
    "        users.append(user_index)\n",
    "        items.append(item_index)\n",
    "        scores.append(score)\n",
    "        if feedback == 'implicit':\n",
    "            inter.setdefault(user_index, []).append(item_index)\n",
    "        else:\n",
    "            inter[item_index, user_index] = score\n",
    "    return users, items, scores, inter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_load_ml100k_pytorch(data_dir:str,split_mode: str = 'seq-aware', feedback: str = 'explicit',\n",
    "                                  test_ratio: float = 0.1, batch_size: int = 256)->tuple[int,int,DataLoader,DataLoader]:\n",
    "    \"\"\"\n",
    "    Split the dataset and load it into PyTorch DataLoader objects.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    split_mode : str, optional\n",
    "        The mode of splitting the data. Can be 'random' or 'seq-aware'. Default is 'seq-aware'.\n",
    "    feedback : str, optional\n",
    "        The type of feedback. Can be 'explicit' or 'implicit'. Default is 'explicit'.\n",
    "    test_ratio : float, optional\n",
    "        The ratio of the dataset to be used as the test set. Only used if split_mode is 'random'. Default is 0.1.\n",
    "    batch_size : int, optional\n",
    "        The size of the batches for the DataLoader. Default is 256.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    tuple[int, int, DataLoader, DataLoader]\n",
    "        A tuple containing:\n",
    "        - num_users: The number of unique users.\n",
    "        - num_items: The number of unique items.\n",
    "        - train_iter: DataLoader for the training set.\n",
    "        - test_iter: DataLoader for the test set.\n",
    "    \"\"\"\n",
    "    data, num_users, num_items = read_data_ml100k(data_dir)\n",
    "    train_data, test_data = split_data_ml100k(\n",
    "        data, num_users, num_items, split_mode, test_ratio)\n",
    "    train_u, train_i, train_r, _ = load_data_ml100k(\n",
    "        train_data, num_users, num_items, feedback)\n",
    "    test_u, test_i, test_r, _ = load_data_ml100k(\n",
    "        test_data, num_users, num_items, feedback)\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    train_u_tensor = torch.tensor(train_u, dtype=torch.long)\n",
    "    train_i_tensor = torch.tensor(train_i, dtype=torch.long)\n",
    "    train_r_tensor = torch.tensor(train_r, dtype=torch.float)\n",
    "    test_u_tensor = torch.tensor(test_u, dtype=torch.long)\n",
    "    test_i_tensor = torch.tensor(test_i, dtype=torch.long)\n",
    "    test_r_tensor = torch.tensor(test_r, dtype=torch.float)\n",
    "    \n",
    "    # Create TensorDataset\n",
    "    train_set = TensorDataset(train_u_tensor, train_i_tensor, train_r_tensor)\n",
    "    test_set = TensorDataset(test_u_tensor, test_i_tensor, test_r_tensor)\n",
    "    \n",
    "    # Create DataLoader\n",
    "    train_iter = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
    "    test_iter = DataLoader(test_set, batch_size=batch_size)\n",
    "    \n",
    "    return num_users, num_items, train_iter, test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF(nn.Module):\n",
    "    def __init__(self, num_factors: int, num_users: int, num_items: int):\n",
    "        \"\"\"\n",
    "        Matrix Factorization model using PyTorch.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        num_factors : int\n",
    "            The number of latent factors.\n",
    "        num_users : int\n",
    "            The number of unique users.\n",
    "        num_items : int\n",
    "            The number of unique items.\n",
    "        \"\"\"\n",
    "        super(MF, self).__init__()\n",
    "        # User latent matrix\n",
    "        self.P = nn.Embedding(num_users, num_factors)\n",
    "        # Item latent matrix\n",
    "        self.Q = nn.Embedding(num_items, num_factors)\n",
    "        self.user_bias = nn.Embedding(num_users, 1)\n",
    "        self.item_bias = nn.Embedding(num_items, 1)\n",
    "\n",
    "    def forward(self, user_id: torch.Tensor, item_id: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass for the model.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        user_id : torch.Tensor\n",
    "            Tensor containing user indices.\n",
    "        item_id : torch.Tensor\n",
    "            Tensor containing item indices.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        torch.Tensor\n",
    "            Predicted ratings.\n",
    "        \"\"\"\n",
    "        P_u = self.P(user_id)\n",
    "        Q_i = self.Q(item_id)\n",
    "        b_u = self.user_bias(user_id).squeeze()\n",
    "        b_i = self.item_bias(item_id).squeeze()\n",
    "        outputs = (P_u * Q_i).sum(dim=1) + b_u + b_i\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net:MF,dataloaders:dict[str,DataLoader],dataset_sizes:dict[str,int],device:torch.device,optimizer:torch.optim.Optimizer,scheduler,num_epochs:int=25)->MF:\n",
    "    \"\"\"\n",
    "    Train the Matrix Factorization (MF) model.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    net : MF\n",
    "        The Matrix Factorization model to be trained.\n",
    "    dataloaders : dict[str, DataLoader]\n",
    "        A dictionary containing the DataLoader objects for training and validation datasets.\n",
    "        Expected keys are 'train' and 'val'.\n",
    "    dataset_sizes : dict[str, int]\n",
    "        A dictionary containing the sizes of the training and validation datasets.\n",
    "        Expected keys are 'train' and 'val'.\n",
    "    device : torch.device\n",
    "        The device to run the training on (e.g., 'cpu' or 'cuda').\n",
    "    optimizer : Optimizer\n",
    "        The optimizer to use for training.\n",
    "    scheduler : _LRScheduler\n",
    "        The learning rate scheduler to use for training.\n",
    "    num_epochs : int, optional\n",
    "        The number of epochs to train the model. Default is 25.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    MF\n",
    "        The trained Matrix Factorization model with the best validation loss.\n",
    "    \"\"\"\n",
    "    since = time.time()\n",
    "\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(net.state_dict(),best_model_params_path)\n",
    "        best_loss = 99999999999\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    net.train()  # Set model to training mode\n",
    "                else:\n",
    "                    net.eval()   # Set model to evaluate mode\n",
    "                \n",
    "                running_loss = 0.0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for user_batch, item_batch, rating_batch in dataloaders[phase]:\n",
    "                    user_batch = user_batch.to(device)\n",
    "                    item_batch = item_batch.to(device)\n",
    "                    rating_batch = rating_batch.to(device)\n",
    "                    \n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase=='train'):\n",
    "                        outputs = net(user_batch,item_batch)\n",
    "                        # apply RMSE as loss function\n",
    "                        criterion = nn.MSELoss()\n",
    "                        loss = torch.sqrt(criterion(outputs, rating_batch))\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * user_batch.size(0)\n",
    "                \n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f}')\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    torch.save(net.state_dict(), best_model_params_path)\n",
    "            print()\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best loss: {best_loss:4f}')\n",
    "\n",
    "        # load best model weights\n",
    "        net.load_state_dict(torch.load(best_model_params_path, weights_only=True))\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n",
      "train Loss: 6.6057\n",
      "val Loss: 6.5009\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 6.2512\n",
      "val Loss: 6.2714\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 5.9118\n",
      "val Loss: 6.0479\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 5.5871\n",
      "val Loss: 5.8340\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 5.2762\n",
      "val Loss: 5.6254\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 4.9782\n",
      "val Loss: 5.4259\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 4.6936\n",
      "val Loss: 5.2336\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 4.4209\n",
      "val Loss: 5.0477\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 4.1588\n",
      "val Loss: 4.8704\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 3.9091\n",
      "val Loss: 4.6979\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 3.7500\n",
      "val Loss: 4.6812\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 3.7262\n",
      "val Loss: 4.6643\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 3.7027\n",
      "val Loss: 4.6475\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 3.6785\n",
      "val Loss: 4.6307\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "train Loss: 3.6547\n",
      "val Loss: 4.6138\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "train Loss: 3.6304\n",
      "val Loss: 4.5969\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "train Loss: 3.6066\n",
      "val Loss: 4.5801\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "train Loss: 3.5823\n",
      "val Loss: 4.5633\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "train Loss: 3.5585\n",
      "val Loss: 4.5466\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "train Loss: 3.5351\n",
      "val Loss: 4.5299\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "train Loss: 3.5188\n",
      "val Loss: 4.5282\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "train Loss: 3.5166\n",
      "val Loss: 4.5266\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "train Loss: 3.5147\n",
      "val Loss: 4.5249\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "train Loss: 3.5120\n",
      "val Loss: 4.5232\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "train Loss: 3.5099\n",
      "val Loss: 4.5215\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "train Loss: 3.5074\n",
      "val Loss: 4.5199\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "train Loss: 3.5050\n",
      "val Loss: 4.5182\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "train Loss: 3.5026\n",
      "val Loss: 4.5165\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "train Loss: 3.5003\n",
      "val Loss: 4.5148\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "train Loss: 3.4979\n",
      "val Loss: 4.5132\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "train Loss: 3.4964\n",
      "val Loss: 4.5130\n",
      "\n",
      "Epoch 31/49\n",
      "----------\n",
      "train Loss: 3.4959\n",
      "val Loss: 4.5128\n",
      "\n",
      "Epoch 32/49\n",
      "----------\n",
      "train Loss: 3.4959\n",
      "val Loss: 4.5127\n",
      "\n",
      "Epoch 33/49\n",
      "----------\n",
      "train Loss: 3.4954\n",
      "val Loss: 4.5125\n",
      "\n",
      "Epoch 34/49\n",
      "----------\n",
      "train Loss: 3.4952\n",
      "val Loss: 4.5123\n",
      "\n",
      "Epoch 35/49\n",
      "----------\n",
      "train Loss: 3.4949\n",
      "val Loss: 4.5122\n",
      "\n",
      "Epoch 36/49\n",
      "----------\n",
      "train Loss: 3.4949\n",
      "val Loss: 4.5120\n",
      "\n",
      "Epoch 37/49\n",
      "----------\n",
      "train Loss: 3.4939\n",
      "val Loss: 4.5118\n",
      "\n",
      "Epoch 38/49\n",
      "----------\n",
      "train Loss: 3.4944\n",
      "val Loss: 4.5117\n",
      "\n",
      "Epoch 39/49\n",
      "----------\n",
      "train Loss: 3.4942\n",
      "val Loss: 4.5115\n",
      "\n",
      "Epoch 40/49\n",
      "----------\n",
      "train Loss: 3.4943\n",
      "val Loss: 4.5115\n",
      "\n",
      "Epoch 41/49\n",
      "----------\n",
      "train Loss: 3.4939\n",
      "val Loss: 4.5115\n",
      "\n",
      "Epoch 42/49\n",
      "----------\n",
      "train Loss: 3.4937\n",
      "val Loss: 4.5115\n",
      "\n",
      "Epoch 43/49\n",
      "----------\n",
      "train Loss: 3.4934\n",
      "val Loss: 4.5115\n",
      "\n",
      "Epoch 44/49\n",
      "----------\n",
      "train Loss: 3.4940\n",
      "val Loss: 4.5114\n",
      "\n",
      "Epoch 45/49\n",
      "----------\n",
      "train Loss: 3.4939\n",
      "val Loss: 4.5114\n",
      "\n",
      "Epoch 46/49\n",
      "----------\n",
      "train Loss: 3.4937\n",
      "val Loss: 4.5114\n",
      "\n",
      "Epoch 47/49\n",
      "----------\n",
      "train Loss: 3.4942\n",
      "val Loss: 4.5114\n",
      "\n",
      "Epoch 48/49\n",
      "----------\n",
      "train Loss: 3.4938\n",
      "val Loss: 4.5114\n",
      "\n",
      "Epoch 49/49\n",
      "----------\n",
      "train Loss: 3.4937\n",
      "val Loss: 4.5114\n",
      "\n",
      "Training complete in 0m 50s\n",
      "Best loss: 4.511390\n"
     ]
    }
   ],
   "source": [
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "else:\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    num_users, num_items, train_iter, test_iter = split_and_load_ml100k_pytorch(DATA_DIR,test_ratio=0.1, batch_size=512)\n",
    "    \n",
    "    dataloaders = {'train':train_iter, 'val':test_iter}\n",
    "    dataset_sizes = {'train':len(train_iter.dataset),'val':len(test_iter.dataset)}\n",
    "    \n",
    "\n",
    "    model = MF(30,num_users,num_items).to(mps_device)\n",
    "    learning_rate = 1e-3\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    model = train_model(model,dataloaders,dataset_sizes,mps_device,optimizer,exp_lr_scheduler,num_epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
